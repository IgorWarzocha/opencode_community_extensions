# Ollamacode Fork (88plug)

**Link:** https://github.com/88plug/ollamacode

**Summary:** A specialized fork of OpenCode optimized for local Ollama model inference, focusing on offline AI coding assistance in the terminal without cloud dependencies. Features include:

- Local Ollama model optimization
- Offline AI coding assistance
- No cloud dependencies required
- Privacy-focused development
- Local model inference
- Terminal-based interface

This fork provides a solution for developers who want to use OpenCode with local models through Ollama, ensuring privacy and offline capability while maintaining the terminal-based workflow.